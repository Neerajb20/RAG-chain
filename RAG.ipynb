{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF text extraction complete! Check extracted_text.txt for output.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file and returns it as a string.\n",
    "    \n",
    "    :param pdf_path: Path to the PDF file\n",
    "    :return: Extracted text as a string\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"/mnt/nvme_disk2/User_data/nb57077k/project/2019BurkovTheHundred-pageMachineLearning.pdf\"  # Change to your actual PDF file path\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Save to a text file for verification\n",
    "with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(extracted_text)\n",
    "\n",
    "print(\"✅ PDF text extraction complete! Check extracted_text.txt for output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paragraphs: 6151\n",
      "✅ Total Chunks: 661\n",
      "\n",
      "Chunk 1:\n",
      "The Hundred- Page Machine Learning Book Andriy Burkov “All models are wrong, but some are useful.” — George Box The book is distributed on the “read ﬁrst, buy later” principle. Andriy Burkov The Hundred-Page Machine Learning Book - Draft Preface Let’s start by telling the truth: machines don’t learn. What a typical “learning machine” does, is ﬁnding a mathematical formula, which, when applied to a collection of inputs (called “training data”), produces the desired outputs. This mathematical formula also generates the correct outputs for most other inputs (distinct from the training data) on the condition that\n",
      "--------------------------------------------------\n",
      "Chunk 2:\n",
      "those inputs come from the same or a similar statistical distribution as the one the training data was drawn from. Why isn’t that learning? Because if you slightly distort the inputs, the output is very likely to become completely wrong. It’s not how learning in animals works. If you learned to play a video game by looking straight at the screen, you would still be a good player if someone rotates the screen slightly. A machine learning algorithm, if it was trained by “looking”\n",
      "--------------------------------------------------\n",
      "Chunk 3:\n",
      "straight at the screen, unless it was also trained to recognize rotation, will fail to play the game on a rotated screen. So why the name “machine learning” then? The reason, as is often the case, is marketing: Arthur Samuel, an American pioneer in the ﬁeld of computer gaming and artiﬁcial intelligence, coined the term in 1959 while at IBM. Similarly to how in the 2010s IBM tried to market the term “cognitive computing” to stand out from competition, in the 1960s, IBM used the new cool term “machine learning” to attract both clients and talented employees.\n",
      "--------------------------------------------------\n",
      "Chunk 4:\n",
      "As you can see, just like artiﬁcial intelligence is not intelligence, machine learning is not learning. However, machine learning is a universally recognized term that usually refers to the science and engineering of building machines capable of doing various useful things without being explicitly programmed to do so. So, the word “learning” in the term is used by analogy with the learning in animals rather than literally. Who This Book is For This book contains only those parts of the vast body of material on machine learning developed\n",
      "--------------------------------------------------\n",
      "Chunk 5:\n",
      "since the 1960s that have proven to have a signiﬁcant practical value. A beginner in machine learning will ﬁnd in this book just enough details to get a comfortable level of understanding of the ﬁeld and start asking the right questions. Practitioners with experience can use this book as a collection of directions for further self-improvement. The book also comes in handy when brainstorming at the beginning of a project, when you try to answer the question whether a given technical or business problem is “machine-learnable” and, if yes, which techniques you should try to solve it.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def chunk_text(text, max_words=100):\n",
    "    \"\"\"\n",
    "    Splits text into chunks while preserving structure.\n",
    "    \n",
    "    - Keeps headings as separate chunks.\n",
    "    - Ensures meaningful splits by using paragraph structure.\n",
    "    \n",
    "    :param text: The extracted text from DOCX.\n",
    "    :param max_words: Maximum words per chunk.\n",
    "    :return: List of text chunks.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    paragraphs = text.split(\"\\n\")\n",
    "    print(f\"Total paragraphs: {len(paragraphs)}\")\n",
    "\n",
    "    for para in paragraphs:\n",
    "        para = para.strip()\n",
    "        if not para:  # Skip empty lines\n",
    "            continue\n",
    "\n",
    "        words = para.split()\n",
    "        \n",
    "        # Treat headings as separate chunks (assumes headings are short)\n",
    "        if len(words) < 8 and re.match(r'^[A-Z ]+$', para):\n",
    "            if current_chunk:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = []\n",
    "                current_length = 0\n",
    "            chunks.append(para)  # Store heading as its own chunk\n",
    "            continue\n",
    "\n",
    "        # If adding paragraph exceeds max_words, save the current chunk\n",
    "        if current_length + len(words) > max_words:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "        # Add paragraph to chunk\n",
    "        current_chunk.append(para)\n",
    "        current_length += len(words)\n",
    "\n",
    "    # Save the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# ✅ **Correcting the issue**\n",
    "extracted_text_file = \"/mnt/nvme_disk2/User_data/nb57077k/project/extracted_text.txt\"\n",
    "\n",
    "# Read the text from the file\n",
    "with open(extracted_text_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    extracted_text = file.read()  # ✅ Read the actual text content\n",
    "\n",
    "# Now, process the text with chunking\n",
    "chunks = chunk_text(extracted_text, max_words=100)\n",
    "\n",
    "# Display total chunks\n",
    "print(f\"✅ Total Chunks: {len(chunks)}\\n\")\n",
    "\n",
    "# Display the first few chunks\n",
    "for i, chunk in enumerate(chunks[:5]):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nvme_disk2/User_data/nb57077k/miniconda3/envs/neeraj/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-10 19:54:43.656771: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 19:54:43.667972: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741616683.681823  539665 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741616683.685909  539665 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 19:54:43.700464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 661 embeddings!\n",
      "Example embedding shape: (384,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Load a pre-trained Sentence-BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Efficient & fast\n",
    "\n",
    "def generate_embeddings(chunks):\n",
    "    \"\"\"\n",
    "    Generates embeddings for text chunks using Sentence-BERT.\n",
    "\n",
    "    :param chunks: List of text chunks\n",
    "    :return: NumPy array of embeddings\n",
    "    \"\"\"\n",
    "    embeddings = model.encode(chunks, convert_to_numpy=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "# Generate embeddings\n",
    "chunk_embeddings = generate_embeddings(chunks)\n",
    "\n",
    "print(f\"✅ Generated {len(chunk_embeddings)} embeddings!\")\n",
    "print(f\"Example embedding shape: {chunk_embeddings[0].shape}\")  # Should be (384,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.81511764e-02, -1.42902024e-02, -1.35886082e-02, -7.83646386e-03,\n",
       "        1.54385704e-03,  5.02703227e-02, -4.08427864e-02, -3.52234989e-02,\n",
       "       -1.31944343e-02,  2.67965458e-02, -1.41763762e-02,  1.09248295e-01,\n",
       "        1.11532860e-01, -7.28432313e-02, -9.96976420e-02,  7.75088230e-03,\n",
       "       -9.77185220e-02,  5.15553579e-02, -1.36999916e-02, -9.19218212e-02,\n",
       "        9.28739086e-03,  3.78383212e-02, -2.86149830e-02,  5.61336316e-02,\n",
       "       -5.88891022e-02,  2.74046548e-02, -7.71183567e-03, -5.30428486e-03,\n",
       "        7.60442903e-03, -1.59289353e-02, -4.41234522e-02,  1.03170034e-02,\n",
       "        3.97144742e-02,  3.88945383e-03, -6.35966659e-02, -1.04297167e-02,\n",
       "       -2.87223551e-02,  2.33911872e-02,  2.89282706e-02,  5.80605119e-02,\n",
       "        4.17400673e-02, -6.20848462e-02, -3.35728228e-02,  5.58815077e-02,\n",
       "        1.35030404e-01,  5.79331890e-02, -5.01126684e-02, -7.08804801e-02,\n",
       "        1.15623726e-02, -6.14022138e-04, -1.32548496e-01,  3.53116840e-02,\n",
       "       -2.33557355e-02,  3.23168896e-02, -1.91116910e-02, -1.80281252e-02,\n",
       "       -2.42782775e-02,  3.94690745e-02, -4.60937023e-02, -2.52478905e-02,\n",
       "        1.76363066e-02, -1.33373454e-01, -1.24920703e-01,  1.26383007e-02,\n",
       "        7.46521354e-02, -3.91200744e-03, -6.68121800e-02,  1.95094645e-02,\n",
       "       -7.32431561e-02, -2.21689399e-02, -1.15088308e-02,  5.79981580e-02,\n",
       "       -4.43509147e-02,  7.31039494e-02,  1.31507628e-02, -1.57621074e-02,\n",
       "        5.39974906e-02,  2.65767332e-02,  4.52510491e-02, -5.09350421e-03,\n",
       "       -5.90070747e-02, -4.24153060e-02,  1.06690982e-02, -2.96010636e-02,\n",
       "        1.43149504e-02, -3.43583189e-02, -2.81609185e-02,  1.62155775e-03,\n",
       "        3.05856299e-02, -1.88179910e-02,  1.32346526e-02, -4.38372865e-02,\n",
       "        2.39645485e-02, -4.11649141e-03, -3.63252610e-02,  8.97738263e-02,\n",
       "       -3.37143056e-03, -2.66542640e-02,  5.37340250e-03,  7.82160684e-02,\n",
       "       -4.53541353e-02,  5.48762791e-02,  8.44543651e-02, -1.50715122e-02,\n",
       "        5.15311472e-02, -3.88104692e-02,  2.60940548e-02,  1.87910236e-02,\n",
       "        7.95941427e-02, -1.34522721e-01, -3.42833553e-03, -7.20311143e-03,\n",
       "        4.29339195e-03,  1.09434295e-02,  3.83781418e-02, -2.93608457e-02,\n",
       "        9.40906350e-03, -1.70357488e-02, -9.60574020e-03,  6.06622137e-02,\n",
       "       -9.48287696e-02, -2.75856927e-02,  3.08248610e-03,  8.76686797e-02,\n",
       "       -3.15689482e-02, -9.32501182e-02, -8.80056247e-02,  1.94505689e-33,\n",
       "        1.64419115e-02, -3.20274010e-02,  2.25939769e-02,  1.33468630e-02,\n",
       "       -1.04531217e-02, -2.69721616e-02, -1.75690372e-02, -3.48158292e-02,\n",
       "        1.12815797e-01,  4.76957224e-02, -6.30807802e-02,  3.17529291e-02,\n",
       "        2.81856209e-02,  1.20793454e-01,  2.46150233e-02,  4.27984670e-02,\n",
       "       -2.15072259e-02,  2.28221528e-02,  3.29383947e-02, -2.75374372e-02,\n",
       "        1.06978424e-01,  2.02602651e-02,  1.83059927e-02, -5.87951988e-02,\n",
       "       -1.82709880e-02,  9.75923017e-02,  3.64150442e-02,  5.53849991e-03,\n",
       "       -2.65968461e-02,  3.53382826e-02,  2.58217677e-02,  7.77630508e-02,\n",
       "       -5.18008228e-03, -4.85599674e-02, -4.81298484e-04, -2.72620004e-02,\n",
       "        2.70952052e-03,  3.39246611e-03,  4.77740951e-02, -2.29432993e-02,\n",
       "       -4.07512784e-02, -1.60428341e-02,  2.75919233e-02, -7.02829659e-02,\n",
       "       -1.73824690e-02, -9.93935391e-03,  3.75085585e-02, -4.29424644e-02,\n",
       "       -3.80427577e-03, -2.36398261e-02, -5.61339967e-02, -3.40227038e-02,\n",
       "       -3.20599601e-02, -8.86699650e-03, -3.05790007e-02,  5.50023429e-02,\n",
       "       -2.56905556e-02,  6.58747479e-02,  9.00846627e-03,  5.85811473e-02,\n",
       "        7.93552026e-02,  4.93481457e-02,  6.42662356e-03,  7.01228976e-02,\n",
       "       -2.60297768e-02,  4.96987328e-02,  1.18101360e-02,  5.04932133e-03,\n",
       "        2.72480100e-02, -1.32080866e-03, -1.01865968e-02, -1.78790148e-02,\n",
       "       -5.71220666e-02, -6.44714013e-02,  8.97748247e-02, -7.96279535e-02,\n",
       "        2.66249049e-02, -4.14547659e-02, -1.14553720e-02, -1.97248086e-02,\n",
       "       -2.08507311e-02,  2.01653261e-02, -3.36326510e-02, -6.29164875e-02,\n",
       "       -3.49685997e-02,  3.44918668e-02, -1.46259582e-02, -3.60407867e-02,\n",
       "       -1.07215950e-02, -2.23744586e-02, -2.54905075e-02,  1.67659717e-03,\n",
       "        9.86606535e-03,  3.05229370e-02, -3.50062102e-02, -2.69583852e-33,\n",
       "       -6.93911165e-02,  1.62291825e-02, -9.28326845e-02,  1.09542802e-01,\n",
       "       -1.33465249e-02,  2.68165227e-02, -7.32524395e-02,  7.00261667e-02,\n",
       "       -1.40020689e-02,  1.52806174e-02,  2.03512330e-02, -5.35286479e-02,\n",
       "        5.98594695e-02,  1.98397450e-02, -3.19896378e-02,  3.09591983e-02,\n",
       "       -1.66615266e-02, -4.70001362e-02, -6.28909692e-02, -3.19495872e-02,\n",
       "       -7.54764862e-03,  5.76661378e-02, -1.77961141e-02, -2.95445719e-03,\n",
       "        4.28925231e-02,  6.99411752e-03, -1.01434523e-02,  6.79928511e-02,\n",
       "       -5.37111051e-02,  3.23308185e-02, -5.12447469e-02, -1.03695258e-01,\n",
       "       -5.41822799e-02,  3.25673148e-02, -5.47361560e-02,  3.20773683e-02,\n",
       "        3.61655056e-02,  1.51255429e-02, -1.90945491e-02,  6.65020049e-02,\n",
       "        4.60493416e-02, -4.40766551e-02, -6.63996115e-02, -7.34437332e-02,\n",
       "       -1.13285799e-02, -7.26072937e-02, -1.39595487e-03, -5.00963517e-02,\n",
       "        4.04103547e-02, -7.67337084e-02,  8.43334123e-02, -3.25910491e-03,\n",
       "        3.96093503e-02, -6.54041171e-02, -1.07708603e-01,  4.70171012e-02,\n",
       "       -3.84647585e-02,  2.85375491e-02,  3.62356007e-02,  4.81109321e-02,\n",
       "       -1.02264635e-01, -5.37992269e-02, -5.06886169e-02,  1.20823517e-01,\n",
       "       -6.10504746e-02, -7.46473065e-03, -5.35296090e-02,  7.84797072e-02,\n",
       "        8.97262767e-02, -2.98296083e-02, -5.65785170e-02,  5.87944910e-02,\n",
       "        1.00984015e-02,  3.32102589e-02, -6.36786968e-02,  8.50462168e-02,\n",
       "       -3.66422683e-02, -7.57795945e-02, -3.59559283e-02, -3.86719815e-02,\n",
       "       -2.79729953e-03,  9.37228836e-03,  1.45405401e-02,  1.30171001e-01,\n",
       "        4.00376283e-02,  2.26909090e-02,  9.83400941e-02, -5.92933483e-02,\n",
       "       -6.46994263e-02, -5.49285300e-02,  1.15842354e-02,  9.49757919e-02,\n",
       "        7.37151504e-03,  9.89013761e-02, -8.53207931e-02, -4.85935807e-08,\n",
       "       -4.07430418e-02,  6.10625185e-03,  1.05941229e-01,  1.22059574e-02,\n",
       "        1.00127883e-01,  2.32182513e-03,  2.87863966e-02,  2.03703139e-02,\n",
       "       -1.03848606e-01, -9.72177181e-03,  5.48997931e-02,  6.58313278e-03,\n",
       "       -1.01109156e-02,  3.43428599e-03,  1.92919020e-02,  1.02459706e-01,\n",
       "        3.56778391e-02,  3.55114564e-02, -2.84766480e-02,  4.21835631e-02,\n",
       "        1.07708625e-01, -3.83800343e-02,  8.29611793e-02, -3.90013168e-03,\n",
       "        7.68528357e-02, -6.36039767e-03, -6.68532252e-02,  7.21880272e-02,\n",
       "        1.06665650e-02,  4.60428521e-02, -5.37783746e-03,  1.30386958e-02,\n",
       "        2.13053860e-02, -4.47818264e-03,  1.04250826e-01,  8.65954086e-02,\n",
       "        3.84841859e-02, -4.51177172e-02, -8.48559514e-02, -7.01955184e-02,\n",
       "       -8.49645287e-02,  9.23555717e-03, -1.30706979e-02,  2.52732802e-02,\n",
       "        6.31371588e-02,  1.35877654e-02, -4.29877918e-03, -6.31406233e-02,\n",
       "       -3.69631946e-02, -6.38472429e-03,  7.99321532e-02,  3.38783413e-02,\n",
       "        6.04764409e-02,  1.02366898e-02,  6.88028336e-02, -3.53064314e-02,\n",
       "        2.51761097e-02, -8.21326450e-02, -6.58688135e-03,  1.14840604e-02,\n",
       "        1.17873112e-02,  1.15377612e-01,  2.56209634e-02, -2.89523266e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings stored in FAISS!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "def store_embeddings_faiss(embeddings):\n",
    "    \"\"\"\n",
    "    Stores embeddings in a FAISS index.\n",
    "\n",
    "    :param embeddings: NumPy array of embeddings\n",
    "    :return: FAISS index\n",
    "    \"\"\"\n",
    "    d = embeddings.shape[1]  # Get embedding dimension\n",
    "    index = faiss.IndexFlatL2(d)  # L2 distance (cosine similarity alternative)\n",
    "    index.add(embeddings)  # Add embeddings to index\n",
    "    return index\n",
    "\n",
    "# Store embeddings in FAISS\n",
    "faiss_index = store_embeddings_faiss(chunk_embeddings)\n",
    "\n",
    "print(\"✅ Embeddings stored in FAISS!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Top Retrieved Chunks:\n",
      "1. which, to be useful, rely on a collection of examples of some phenomenon. These examples can come from nature, be handcrafted by humans or generated by another algorithm. Machine learning can also be deﬁned as the process of solving a practical problem by 1) gathering a dataset, and 2) algorithmically building a statistical model based on that dataset. That statistical model is assumed to be used somehow to solve the practical problem. To save keystrokes, I use the terms “learning” and “machine learning” interchangeably. 1.2 Types of Learning Learning can be supervised, semi-supervised, unsupervised and reinforcement. 1.2.1 Supervised Learning\n",
      "\n",
      "2. As you can see, just like artiﬁcial intelligence is not intelligence, machine learning is not learning. However, machine learning is a universally recognized term that usually refers to the science and engineering of building machines capable of doing various useful things without being explicitly programmed to do so. So, the word “learning” in the term is used by analogy with the learning in animals rather than literally. Who This Book is For This book contains only those parts of the vast body of material on machine learning developed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def query_faiss(query_text, model, index, chunks, top_k=2):\n",
    "    \"\"\"\n",
    "    Finds the most relevant text chunks for a given query.\n",
    "\n",
    "    :param query_text: User's query\n",
    "    :param model: Sentence-BERT model\n",
    "    :param index: FAISS index\n",
    "    :param chunks: Original text chunks\n",
    "    :param top_k: Number of results to return\n",
    "    :return: List of top retrieved chunks\n",
    "    \"\"\"\n",
    "    query_embedding = model.encode([query_text], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, top_k)  # Search FAISS index\n",
    "    results = [chunks[idx] for idx in indices[0]]\n",
    "    return results\n",
    "\n",
    "# Example query\n",
    "query = \"What is Machine learning?\"\n",
    "retrieved_chunks = query_faiss(query, model, faiss_index, chunks)\n",
    "\n",
    "print(\"\\n🔍 Top Retrieved Chunks:\")\n",
    "for i, chunk in enumerate(retrieved_chunks):\n",
    "    print(f\"{i+1}. {chunk}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-CPP Installed At: /mnt/nvme_disk2/User_data/nb57077k/miniconda3/envs/neeraj/lib/python3.9/site-packages/llama_cpp\n"
     ]
    }
   ],
   "source": [
    "import llama_cpp\n",
    "import os\n",
    "\n",
    "print(\"Llama-CPP Installed At:\", os.path.dirname(llama_cpp.__file__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Introduction to Machine Learning**\n",
      "=====================================\n",
      "\n",
      "Machine learning is a subfield of artificial intelligence that involves the development of algorithms and statistical models that enable machines to perform tasks without being explicitly programmed. The term \"machine learning\" is often used interchangeably with \"learning,\" although it is essential to note that machine learning is not literally learning, but rather a process that draws inspiration from the way animals learn.\n",
      "\n",
      "**Definition of Machine Learning**\n",
      "--------------------------------\n",
      "\n",
      "Machine learning can be defined as the process of solving practical problems by:\n",
      "\n",
      "1. **Gathering a dataset**: Collecting examples of a phenomenon, which can come from nature, be handcrafted by humans, or generated by another algorithm.\n",
      "2. **Algorithmically building a statistical model**: Using the collected dataset to build a statistical model that can be used to solve the practical problem.\n",
      "\n",
      "**Types of Machine Learning**\n",
      "---------------------------\n",
      "\n",
      "There are four primary types of machine learning:\n",
      "\n",
      "1. **Supervised Learning**: In this type of learning, the machine is trained on labeled data, where the correct output is already known.\n",
      "2. **Semi-Supervised Learning**: This type of learning combines both labeled and unlabeled data to train the machine.\n",
      "3. **Unsupervised Learning**: In unsupervised learning, the machine is trained on unlabeled data, and it must find patterns or structure in the data on its own.\n",
      "4. **Reinforcement Learning**: This type of learning involves training the machine through trial and error by providing feedback in the form of rewards or penalties.\n",
      "\n",
      "**Key Characteristics of Machine Learning**\n",
      "-----------------------------------------\n",
      "\n",
      "Machine learning is characterized by its ability to enable machines to perform tasks without being explicitly programmed. The \"learning\" in machine learning refers to the process of improving the performance of a machine on a task over time, based on experience or data. This is analogous to the way animals learn, but it is not literally learning.\n",
      "\n",
      "**Importance of Machine Learning**\n",
      "--------------------------------\n",
      "\n",
      "Machine learning has numerous applications in various fields, including computer vision, natural language processing, speech recognition, and decision-making systems. Its ability to enable machines to perform tasks without being explicitly programmed makes it a vital tool for solving complex problems and improving the efficiency of various processes.\n",
      "\n",
      "In conclusion, machine learning is a subfield of artificial intelligence that involves the development of algorithms and statistical models that enable machines to perform tasks without being explicitly programmed. It relies on the collection of examples of a phenomenon and the use of these examples to build a statistical model that can be used to solve practical problems. With its various types and applications, machine learning has become an essential tool in many fields, and its importance is expected to continue growing in the future.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "def query_ollama_rag(query, retrieved_chunks):\n",
    "    \"\"\"\n",
    "    Sends a retrieval-augmented query to the running LLaMA 3 model via Ollama API.\n",
    "    \n",
    "    :param query: User's question\n",
    "    :param retrieved_chunks: Retrieved text chunks from FAISS\n",
    "    :return: AI-generated structured response\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine retrieved chunks into a context string\n",
    "    context = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # Define structured prompt for RAG retrieval\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant. Answer the following query using the provided context. \n",
    "    Ensure that the answer is structured, detailed, and well-explained.\n",
    "\n",
    "    Query:{query}\n",
    "\n",
    "    Context: {context}\n",
    "    \"\"\"\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    data = {\n",
    "        \"model\": \"llama3.3:70b-instruct-q6_K\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    " \n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    return response.json()[\"response\"]\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "query = \"What is Machine Learning?\"\n",
    "retrieved_chunks = query_faiss(query, model, faiss_index, chunks)\n",
    "structured_answer = query_ollama_rag(query, retrieved_chunks)\n",
    "print(structured_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
